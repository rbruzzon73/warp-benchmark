
# warp-benchmark scripts

*warp-benchmark-v2.sh is the last version released*

## Notes warp-benchmark.sh (V1):
- warp-benchmark.sh is based on Warp MinIO's S3 benchmarking tool designed to measure and analyze object storage performance. 
- The Warp tool generats realistic workloads and provides detailed performance metrics for S3-compatible storage systems.
- This warp-benchmark.sh script executes PUT and GET benchmarks that can be customized and adjusted to meet various requirements regarding size, duration, parallelism, and delay (sleep) between the two benchmark executions.  
- The operations are performed sequentially as detailed below:
   ~~~
   [1/8] Creating namespace 'warp-benchmark'...
   [2/8] Creating ObjectBucketClaim...
   [3/8] Waiting for OBC to be bound (provisioning bucket)...
   [4/8] Extracting credentials...
   [5/8] Deploying Warp Runner Pod...
   [6/8] Running PUT Benchmark...
   [7/8] Sleeping for 2m before GET benchmark...
   [8/8] Running GET Benchmark...
   ~~~

## Notes warp-benchmark-v2.sh (V2):
- warp-benchmark-v2.sh delete the old warp POD and regenerate a new one before starting all benchmark tests.
- warp url image updated to: quay.io/minio/warp:latest
- V2 expands the Benchmark tests to include the Mixed scenario, based on the percentage of GETs and PUTs:
   ~~~
   [1/11] Creating namespace 'warp-benchmark'...
   [2/11] Creating ObjectBucketClaim...
   [3/11] Waiting for OBC to be bound (provisioning bucket)...
   [4/11] Extracting credentials...
   [5/11] Clenup old Warp Running Pod
   [6/11] Deploying Warp Runner Pod..
   [7/11] Running GET Benchmark...
   [8/11] Sleeping for 10s before GET benchmark..
   [9/11] Running PUT Benchmark...
   [10/11] Sleeping for 10s before MIXED benchmark...
   [11/11] Running MIXED Benchmark...
   ~~~ 
   
## Variables customizable in the run-warp-benchmark script.
The warp-benchmark scripts support the customization of the following Variables: 

       # Configuration:
       NAMESPACE="warp-benchmark"
       OBC_NAME="warp-benchmark-bucket"
       STORAGE_CLASS="openshift-storage.noobaa.io"
       LOG_PREFIX="custom-run"

       # Warp Benchmark Settings:
       WARP_CONCURRENT=10         # Number of concurrent operations
       WARP_OBJ_SIZE="1536KiB"    # Object size
       WARP_GET_OBJECTS=100       # Number of objects for GET/MIXED benchmark
       BENCHMARK_PAUSE="10s"       # Time to sleep between benchmarks

       # Durations:
       WARP_DURATION_PUT="30s"    # Duration for PUT benchmark
       WARP_DURATION_GET="30s"    # Duration for GET benchmark
       WARP_DURATION_MIXED="30s"  # Duration for MIXED benchmark (only v2 script)

       # Mixed Ration (only v2 script):
       # Note: The amount of DELETE operations. Must be same or lower than WARP_MIXED_PUT_RATIO
       WARP_MIXED_GET_RATIO=50        # Mixed Ratio: % of operations that are GETs.
       WARP_MIXED_PUT_RATIO=50        # Mixed Ratio: % of operations that are GETs.
       WARP_MIXED_DELETE_RATIO=0      # Mixed Ratio: % of operations that are DELETEs. 
       WARP_MIXED_STAT_RATIO=0        # Mixed Ratio: % of operations that are STATs.
       ~~~
       
## Output details:
- The output includes throughput measured in MB/s showing data transfer rates. 
- Operations per second display how many GET / PUT requests the system can handle. 
- Latency percentiles show response times at p50, p90, p99, and p99.9 levels for operations.
- TTFB is the time from request was sent to the first byte was received.
- During the mixed operations phase, the command executes operations according to the configured distribution.
- The mixed benchmark randomly selects operation types based on the distribution percentages.

## Usefull links:
- [MinIO warp](https://docs.min.io/enterprise/minio-warp).
- [Throughput](https://docs.min.io/enterprise/minio-warp/reference/#throughput).
- [Operations per second](https://docs.min.io/enterprise/minio-warp/reference/#operations-per-second).
- [Latency percentiles](https://docs.min.io/enterprise/minio-warp/reference/#latency-metrics).

## Example of the output generated by warp-benchmark.sh
~~~
[root@dr-ocp-bastion-server ~]# ./run-warp-benchmark-v2.sh
--- Starting Warp Benchmark Automation ---
Settings: Concurrent=10, Size=1536KiB
Pause between benchmarks: 2m
[1/8] Creating namespace 'warp-benchmark'...
Namespace 'warp-benchmark' already exists. Switching to it.
Already on project "warp-benchmark" on server "https://api.ocp4-dr.test.com:6443".
[2/8] Creating ObjectBucketClaim...
objectbucketclaim.objectbucket.io/warp-benchmark-bucket unchanged
[3/8] Waiting for OBC to be bound (provisioning bucket)...
OBC is Bound.
[4/8] Extracting credentials...
Endpoint: s3.openshift-storage.svc
Bucket:   warp-bucket-8607a15b-d2be-4e62-bf01-cfa16760b73b
[5/8] Deploying Warp Runner Pod...
pod/warp-runner unchanged
Waiting for Pod to be Ready...
pod/warp-runner condition met
[6/8] Running PUT Benchmark...
---------------------------------------------------
>>> Starting PUT Benchmark (30s)...
    Saving to: custom-run-put-20260109-101745.json.zst
>>> Analyzing PUT Results:


Report: PUT (185 reqs). Ran Duration: 28s, starting 10:17:54 UTC
 * Objects per request: 1. Size: 1572864 bytes. Concurrency: 10.
 * Average: 8.98 MiB/s, 5.98 obj/s (28s)
 * Reqs: Avg: 1614.9ms, 50%: 1687.4ms, 90%: 1902.0ms, 99%: 2037.5ms, Fastest: 597.5ms, Slowest: 2451.8ms, StdDev: 262.9ms

Throughput, split into 28 x 1s:
 * Fastest: 10.3MiB/s, 6.85 obj/s (1s, starting 10:18:14 UTC)
 * 50% Median: 9.1MiB/s, 6.09 obj/s (1s, starting 10:17:56 UTC)
 * Slowest: 7.1MiB/s, 4.74 obj/s (1s, starting 10:17:52 UTC)


---------------------------------------------------
[7/8] Sleeping for 2m before GET benchmark...
Resuming...
---------------------------------------------------
[8/8] Running GET Benchmark...
>>> Starting GET Benchmark (30s)...
    Saving to: custom-run-get-20260109-102028.json.zst
>>> Analyzing GET Results:


Report: GET (527 reqs). Ran Duration: 27s, starting 10:21:21 UTC
 * Objects per request: 1. Size: 1572864 bytes. Concurrency: 10.
 * Average: 26.18 MiB/s, 17.45 obj/s (27s)
 * Reqs: Avg: 630.7ms, 50%: 636.9ms, 90%: 947.9ms, 99%: 1221.7ms, Fastest: 28.6ms, Slowest: 1417.0ms, StdDev: 245.0ms
 * TTFB: Avg: 576ms, Best: 23ms, 25th: 393ms, Median: 557ms, 75th: 774ms, 90th: 880ms, 99th: 1.157s, Worst: 1.389s StdDev: 232ms

Throughput, split into 27 x 1s:
 * Fastest: 36.1MiB/s, 24.10 obj/s (1s, starting 10:21:42 UTC)
 * 50% Median: 26.3MiB/s, 17.55 obj/s (1s, starting 10:21:43 UTC)
 * Slowest: 19.4MiB/s, 12.95 obj/s (1s, starting 10:21:24 UTC)


---------------------------------------------------
Benchmark Complete.
---------------------------------------------------

-------------------- NOTES ------------------------
---------------------------------------------------
The output includes throughput measured in MB/s showing data transfer rates.
Operations per second display how many GET / PUT requests the system can handle.
Latency percentiles show response times at p50, p90, p99, and p99.9 levels for operations.
Links:
Throughput -> https://docs.min.io/enterprise/minio-warp/reference/#throughput
Operations per second -> https://docs.min.io/enterprise/minio-warp/reference/#operations-per-second
Latency percentiles -> https://docs.min.io/enterprise/minio-warp/reference/#latency-metrics
~~~

## Example of the output generated by warp-benchmark-v2.sh
~~~
[root@dr-ocp-bastion-server ~]# ./run-warp-benchmark-v2.sh
--- Starting Warp Benchmark Automation ---
Settings: Concurrent=10, Size=1536KiB
Mixed Ratio: 50% GETs - 50% PUTs - 0% DELETEs - 0% STATs
Pause between benchmarks: 10s
[1/11] Creating namespace 'warp-benchmark'...
Namespace 'warp-benchmark' already exists. Switching to it.
Already on project "warp-benchmark" on server "https://api.ocp4-dr.test.com:6443".
[2/11] Creating ObjectBucketClaim...
objectbucketclaim.objectbucket.io/warp-benchmark-bucket unchanged
[3/11] Waiting for OBC to be bound (provisioning bucket)...
OBC is Bound.
[4/11] Extracting credentials...
Endpoint: s3.openshift-storage.svc
Bucket:   warp-bucket-6029b3df-7530-4cc3-a0eb-9ed53edd6b64
[5/11] Clenup old Warp Running Pod
Deleting old 'warp-runner' pod...
Old pod removed.
[6/11] Deploying Warp Runner Pod...
Warning: would violate PodSecurity "restricted:latest": allowPrivilegeEscalation != false (container "warp" must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container "warp" must set securityContext.capabilities.drop=["ALL"]), runAsNonRoot != true (pod or container "warp" must set securityContext.runAsNonRoot=true), seccompProfile (pod or container "warp" must set securityContext.seccompProfile.type to "RuntimeDefault" or "Localhost")
pod/warp-runner created
Waiting for Pod to be Ready...
pod/warp-runner condition met
[7/11] Running GET Benchmark...
---------------------------------------------------
>>> Starting GET Benchmark (30s)...
    Saving to: custom-run-get-20260109-143420.json.zst
>>> Analyzing GET Results:


Report: GET (911 reqs). Ran Duration: 27s, starting 14:34:41 UTC
 * Objects per request: 1. Size: 1572864 bytes. Concurrency: 10.
 * Average: 45.82 MiB/s, 30.55 obj/s (27s)
 * Reqs: Avg: 545.3ms, 50%: 532.4ms, 90%: 834.4ms, 99%: 1117.8ms, Fastest: 44.7ms, Slowest: 1967.0ms, StdDev: 212.5ms
 * TTFB: Avg: 470ms, Best: 32ms, 25th: 322ms, Median: 454ms, 75th: 606ms, 90th: 727ms, 99th: 991ms, Worst: 1.68s StdDev: 196ms

Throughput, split into 27 x 1s:
 * Fastest: 99.4MiB/s, 66.26 obj/s (1s, starting 14:35:04 UTC)
 * 50% Median: 43.7MiB/s, 29.16 obj/s (1s, starting 14:34:48 UTC)
 * Slowest: 10.2MiB/s, 6.83 obj/s (1s, starting 14:34:42 UTC)


---------------------------------------------------
[8/11] Sleeping for 10s before PUT benchmark...
Resuming...
---------------------------------------------------
[9/11] Running PUT Benchmark...
>>> Starting PUT Benchmark (30s)...
    Saving to: custom-run-put-20260109-143522.json.zst
>>> Analyzing PUT Results:


Report: PUT (260 reqs). Ran Duration: 28s, starting 14:35:27 UTC
 * Objects per request: 1. Size: 1572864 bytes. Concurrency: 10.
 * Average: 12.88 MiB/s, 8.58 obj/s (28s)
 * Reqs: Avg: 1117.2ms, 50%: 1094.1ms, 90%: 1417.3ms, 99%: 1733.1ms, Fastest: 460.5ms, Slowest: 2357.5ms, StdDev: 222.2ms

Throughput, split into 28 x 1s:
 * Fastest: 16.3MiB/s, 10.89 obj/s (1s, starting 14:35:43 UTC)
 * 50% Median: 13.1MiB/s, 8.71 obj/s (1s, starting 14:35:47 UTC)
 * Slowest: 9.2MiB/s, 6.14 obj/s (1s, starting 14:35:25 UTC)


---------------------------------------------------
[10/11] Sleeping for 10s before MIXED benchmark...
Resuming...
---------------------------------------------------
[11/11] Running MIXED Benchmark...
>>> Starting MIXED Benchmark (30s)...
    Ratio: 50% GETs + 50% PUTs + 0% DELETEs + 0% STATs 
    Saving to: custom-run-mixed-20260109-143611.json.zst
>>> Analyzing MIXED Results:


Report: GET (192 reqs). Ran Duration: 27s, starting 14:36:28 UTC
 * Objects per request: 1. Size: 1572864 bytes. Concurrency: 10.
 * Average: 8.86 MiB/s, 5.91 obj/s (27s)
 * Reqs: Avg: 373.2ms, 50%: 304.9ms, 90%: 863.4ms, 99%: 1114.3ms, Fastest: 34.9ms, Slowest: 1372.1ms, StdDev: 298.2ms
 * TTFB: Avg: 343ms, Best: 26ms, 25th: 116ms, Median: 293ms, 75th: 573ms, 90th: 818ms, 99th: 1.048s, Worst: 1.349s StdDev: 277ms

Throughput, split into 27 x 1s:
 * Fastest: 21.4MiB/s, 14.25 obj/s (1s, starting 14:36:52 UTC)
 * 50% Median: 8.3MiB/s, 5.54 obj/s (1s, starting 14:36:33 UTC)
 * Slowest: 3.0MiB/s, 2.00 obj/s (1s, starting 14:36:43 UTC)

──────────────────────────────────

Report: PUT (204 reqs). Ran Duration: 28s, starting 14:36:28 UTC
 * Objects per request: 1. Size: 1572864 bytes. Concurrency: 10.
 * Average: 10.13 MiB/s, 6.75 obj/s (28s)
 * Reqs: Avg: 1097.9ms, 50%: 1181.9ms, 90%: 1820.0ms, 99%: 2524.8ms, Fastest: 288.5ms, Slowest: 3412.9ms, StdDev: 561.1ms

Throughput, split into 28 x 1s:
 * Fastest: 13.7MiB/s, 9.13 obj/s (1s, starting 14:36:36 UTC)
 * 50% Median: 10.4MiB/s, 6.95 obj/s (1s, starting 14:36:34 UTC)
 * Slowest: 4.9MiB/s, 3.29 obj/s (1s, starting 14:36:45 UTC)


──────────────────────────────────

Report: Total (396 reqs). Ran Duration: 28s, starting 14:36:28 UTC
 * Objects per request: 1. Size: 1572864 bytes. Concurrency: 10.
 * Average: 19.07 MiB/s, 12.71 obj/s (28s)

Throughput, split into 28 x 1s:
 * Fastest: 28.2MiB/s, 18.82 obj/s (1s, starting 14:36:52 UTC)
 * 50% Median: 18.6MiB/s, 12.39 obj/s (1s, starting 14:36:29 UTC)
 * Slowest: 11.3MiB/s, 7.52 obj/s (1s, starting 14:36:43 UTC)

---------------------------------------------------
Benchmark Complete.
---------------------------------------------------

-------------------- NOTES ------------------------
---------------------------------------------------
The output includes throughput measured in MB/s showing data transfer rates.
Operations per second display how many GET / PUT requests the system can handle.
Latency percentiles show response times at p50, p90, p99, and p99.9 levels for operations.
Links:
Throughput -> https://docs.min.io/enterprise/minio-warp/reference/#throughput
Operations per second -> https://docs.min.io/enterprise/minio-warp/reference/#operations-per-second
Latency percentiles -> https://docs.min.io/enterprise/minio-warp/reference/#latency-metrics
~~~
