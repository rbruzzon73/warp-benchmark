
# warp-benchmark scripts

*Point Of Attention: warp-benchmark-v2.sh is the last version released*

## Notes warp-benchmark.sh (V1 - OLD version):
- warp-benchmark.sh is based on Warp MinIO's S3 benchmarking tool designed to measure and analyze object storage performance. 
- The Warp tool generats realistic workloads and provides detailed performance metrics for S3-compatible storage systems.
- This warp-benchmark.sh script executes PUT and GET benchmarks that can be customized and adjusted to meet various requirements regarding size, duration, parallelism, and delay (sleep) between the two benchmark executions.  
- The operations are performed sequentially as detailed below:
   ~~~
   [1/8] Creating namespace 'warp-benchmark'...
   [2/8] Creating ObjectBucketClaim...
   [3/8] Waiting for OBC to be bound (provisioning bucket)...
   [4/8] Extracting credentials...
   [5/8] Deploying Warp Runner Pod...
   [6/8] Running PUT Benchmark...
   [7/8] Sleeping for 2m before GET benchmark...
   [8/8] Running GET Benchmark...
   ~~~

## Notes warp-benchmark-v2.sh (V2 - CURRENT version):
- warp-benchmark-v2.sh delete the old warp POD and regenerate a new one before starting all benchmark tests.
- warp url image updated to: quay.io/minio/warp:latest
- Warp ObjectBucketClaim recreated
- Usage: ./warp-benchmark-v2.sh [mixed|standard|all]
- V2 expands the Benchmark tests to include the Mixed scenario, based on the percentage of GETs and PUTs:
   ~~~
   # GET and PUT benchmarcs
   [1/11] Creating namespace 'warp-benchmark'...
   [2/11] Deleting and re-creating ObjectBucketClaim ...
   [3/11] Waiting for OBC to be bound (provisioning bucket)...
   [4/11] Extracting credentials...
   [5/11] Clenup old Warp Running Pod
   [6/11] Deploying Warp Runner Pod...
   [7/11] Running GET Benchmark...
   [8/11] Sleeping for 30s before PUT benchmark...
   [9/11] Running PUT Benchmark...
   # MIXED benchmarcs
   [1/11] Creating namespace 'warp-benchmark'...
   [2/11] Deleting and re-creating ObjectBucketClaim warp-benchmark-bucket-tf7w...
   [3/11] Waiting for OBC to be bound (provisioning bucket)...
   [4/11] Extracting credentials...
   [5/11] Clenup old Warp Running Pod
   [6/11] Deploying Warp Runner Pod...
   [10/11] Running MIXED Benchmark...
   [11/11] Benchmarks Complete.
   ~~~ 
   
## Variables customizable in the run-warp-benchmark-v2.sh script.
The warp-benchmark scripts support the customization of the following Variables: 

       # Configuration:
       NAMESPACE="warp-benchmark"
       STORAGE_CLASS="openshift-storage.noobaa.io"
       LOG_PREFIX="custom-run"
       CLEAN_OBC_TIMEOUT="240s"   # Timeout for OBC deletion
       POD_ODB_PAUSE=30           # Sleep applied to ODB post deletion and POD post creation

       # Warp Benchmark Settings:
       WARP_CONCURRENT=10         # Number of concurrent operations
       WARP_OBJ_SIZE="1536KiB"    # Object size
       WARP_GET_OBJECTS=100       # Number of objects for GET/MIXED benchmark
       BENCHMARK_PAUSE="10s"       # Time to sleep between benchmarks

       # Durations:
       WARP_DURATION_PUT="30s"    # Duration for PUT benchmark
       WARP_DURATION_GET="30s"    # Duration for GET benchmark
       WARP_DURATION_MIXED="30s"  # Duration for MIXED benchmark

       # Mixed Ration:
       # Note: The amount of DELETE operations. Must be same or lower than WARP_MIXED_PUT_RATIO
       WARP_MIXED_GET_RATIO=50        # Mixed Ratio: % of operations that are GETs.
       WARP_MIXED_PUT_RATIO=50        # Mixed Ratio: % of operations that are GETs.
       WARP_MIXED_DELETE_RATIO=0      # Mixed Ratio: % of operations that are DELETEs. 
       WARP_MIXED_STAT_RATIO=0        # Mixed Ratio: % of operations that are STATs.
       ~~~
       
## Output details:
- The output includes throughput measured in MB/s showing data transfer rates. 
- Operations per second display how many GET / PUT requests the system can handle. 
- Latency percentiles show response times at p50, p90, p99, and p99.9 levels for operations.
- TTFB is the time from request was sent to the first byte was received.
- During the mixed operations phase, the command executes operations according to the configured distribution.
- The mixed benchmark randomly selects operation types based on the distribution percentages.

## Usefull links:
- [MinIO warp](https://docs.min.io/enterprise/minio-warp).
- [Throughput](https://docs.min.io/enterprise/minio-warp/reference/#throughput).
- [Operations per second](https://docs.min.io/enterprise/minio-warp/reference/#operations-per-second).
- [Latency percentiles](https://docs.min.io/enterprise/minio-warp/reference/#latency-metrics).

## Example of the output generated by warp-benchmark.sh
~~~
[root@dr-ocp-bastion-server ~]# ./run-warp-benchmark-v2.sh
--- Starting Warp Benchmark Automation ---
Settings: Concurrent=10, Size=1536KiB
Pause between benchmarks: 2m
[1/8] Creating namespace 'warp-benchmark'...
Namespace 'warp-benchmark' already exists. Switching to it.
Already on project "warp-benchmark" on server "https://api.ocp4-dr.test.com:6443".
[2/8] Creating ObjectBucketClaim...
objectbucketclaim.objectbucket.io/warp-benchmark-bucket unchanged
[3/8] Waiting for OBC to be bound (provisioning bucket)...
OBC is Bound.
[4/8] Extracting credentials...
Endpoint: s3.openshift-storage.svc
Bucket:   warp-bucket-8607a15b-d2be-4e62-bf01-cfa16760b73b
[5/8] Deploying Warp Runner Pod...
pod/warp-runner unchanged
Waiting for Pod to be Ready...
pod/warp-runner condition met
[6/8] Running PUT Benchmark...
---------------------------------------------------
>>> Starting PUT Benchmark (30s)...
    Saving to: custom-run-put-20260109-101745.json.zst
>>> Analyzing PUT Results:


Report: PUT (185 reqs). Ran Duration: 28s, starting 10:17:54 UTC
 * Objects per request: 1. Size: 1572864 bytes. Concurrency: 10.
 * Average: 8.98 MiB/s, 5.98 obj/s (28s)
 * Reqs: Avg: 1614.9ms, 50%: 1687.4ms, 90%: 1902.0ms, 99%: 2037.5ms, Fastest: 597.5ms, Slowest: 2451.8ms, StdDev: 262.9ms

Throughput, split into 28 x 1s:
 * Fastest: 10.3MiB/s, 6.85 obj/s (1s, starting 10:18:14 UTC)
 * 50% Median: 9.1MiB/s, 6.09 obj/s (1s, starting 10:17:56 UTC)
 * Slowest: 7.1MiB/s, 4.74 obj/s (1s, starting 10:17:52 UTC)


---------------------------------------------------
[7/8] Sleeping for 2m before GET benchmark...
Resuming...
---------------------------------------------------
[8/8] Running GET Benchmark...
>>> Starting GET Benchmark (30s)...
    Saving to: custom-run-get-20260109-102028.json.zst
>>> Analyzing GET Results:


Report: GET (527 reqs). Ran Duration: 27s, starting 10:21:21 UTC
 * Objects per request: 1. Size: 1572864 bytes. Concurrency: 10.
 * Average: 26.18 MiB/s, 17.45 obj/s (27s)
 * Reqs: Avg: 630.7ms, 50%: 636.9ms, 90%: 947.9ms, 99%: 1221.7ms, Fastest: 28.6ms, Slowest: 1417.0ms, StdDev: 245.0ms
 * TTFB: Avg: 576ms, Best: 23ms, 25th: 393ms, Median: 557ms, 75th: 774ms, 90th: 880ms, 99th: 1.157s, Worst: 1.389s StdDev: 232ms

Throughput, split into 27 x 1s:
 * Fastest: 36.1MiB/s, 24.10 obj/s (1s, starting 10:21:42 UTC)
 * 50% Median: 26.3MiB/s, 17.55 obj/s (1s, starting 10:21:43 UTC)
 * Slowest: 19.4MiB/s, 12.95 obj/s (1s, starting 10:21:24 UTC)


---------------------------------------------------
Benchmark Complete.
---------------------------------------------------

-------------------- NOTES ------------------------
---------------------------------------------------
The output includes throughput measured in MB/s showing data transfer rates.
Operations per second display how many GET / PUT requests the system can handle.
Latency percentiles show response times at p50, p90, p99, and p99.9 levels for operations.
Links:
Throughput -> https://docs.min.io/enterprise/minio-warp/reference/#throughput
Operations per second -> https://docs.min.io/enterprise/minio-warp/reference/#operations-per-second
Latency percentiles -> https://docs.min.io/enterprise/minio-warp/reference/#latency-metrics
~~~

## Example of the output generated by "vi aawarp-benchmark-v2.sh all"
~~~
[root@dr-ocp-bastion-server ~]# ./warp-benchmark-v2.sh all
#------ Executing Workload: all - 2026-01-09 15:32:01 -------#
Settings: Concurrent=10, Size=1536KiB
Mixed Ratio: 50% GETs - 50% PUTs - 0% DELETEs - 0% STATs
Pause between benchmarks: 30s

# Start GET and PUT benchmarks
[1/11] Creating namespace 'warp-benchmark'...
Namespace 'warp-benchmark' already exists. Switching to it.
Already on project "warp-benchmark" on server "https://api.ocp4-dr.test.com:6443".
[2/11] Deleting and re-creating ObjectBucketClaim ...
Deleting found OBCs...
objectbucketclaim.objectbucket.io "warp-benchmark-bucket" deleted
objectbucketclaim.objectbucket.io/warp-benchmark-bucket-tf7w created
[3/11] Waiting for OBC to be bound (provisioning bucket)...
Waiting for bucket provisioning...
OBC is Bound.
[4/11] Extracting credentials...
Endpoint: s3.openshift-storage.svc
Bucket:   warp-bucket-db36ff66-d83f-4aca-83de-20a828f309b7
[5/11] Clenup old Warp Running Pod
Deleting old 'warp-runner' pod...
Old pod removed.
[6/11] Deploying Warp Runner Pod...
pod/warp-runner created
Waiting for Pod to be Ready...
pod/warp-runner condition met
..............................
[7/11] Running GET Benchmark...
---------------------------------------------------
>>> Starting GET Benchmark (30s)...
    Saving to: /tmp/custom-run-get-20260109-203317.json.zst
>>> Analyzing GET Results:


Report: GET (995 reqs). Ran Duration: 27s, starting 20:33:32 UTC
 * Objects per request: 1. Size: 1572864 bytes. Concurrency: 10.
 * Average: 51.90 MiB/s, 34.60 obj/s (27s)
 * Reqs: Avg: 347.5ms, 50%: 318.3ms, 90%: 646.7ms, 99%: 859.3ms, Fastest: 55.8ms, Slowest: 1451.3ms, StdDev: 194.1ms
 * TTFB: Avg: 300ms, Best: 43ms, 25th: 161ms, Median: 272ms, 75th: 381ms, 90th: 549ms, 99th: 773ms, Worst: 1.208s StdDev: 168ms

Throughput, split into 27 x 1s:
 * Fastest: 106.5MiB/s, 71.03 obj/s (1s, starting 20:33:42 UTC)
 * 50% Median: 53.6MiB/s, 35.76 obj/s (1s, starting 20:33:56 UTC)
 * Slowest: 14.8MiB/s, 9.84 obj/s (1s, starting 20:33:31 UTC)


---------------------------------------------------
[8/11] Sleeping for 30s before PUT benchmark...
./warp-benchmark-v2.sh: line 230: ((: i<=30s: value too great for base (error token is "30s")
Resuming...
---------------------------------------------------
[9/11] Running PUT Benchmark...
---------------------------------------------------
>>> Starting PUT Benchmark (30s)...
    Saving to: /tmp/custom-run-put-20260109-203403.json.zst
>>> Analyzing PUT Results:


Report: PUT (282 reqs). Ran Duration: 27s, starting 20:34:08 UTC
 * Objects per request: 1. Size: 1572864 bytes. Concurrency: 10.
 * Average: 13.85 MiB/s, 9.23 obj/s (27s)
 * Reqs: Avg: 1082.7ms, 50%: 1056.0ms, 90%: 1407.2ms, 99%: 1572.5ms, Fastest: 450.3ms, Slowest: 1634.9ms, StdDev: 243.7ms

Throughput, split into 27 x 1s:
 * Fastest: 17.0MiB/s, 11.33 obj/s (1s, starting 20:34:18 UTC)
 * 50% Median: 14.0MiB/s, 9.33 obj/s (1s, starting 20:34:12 UTC)
 * Slowest: 11.0MiB/s, 7.36 obj/s (1s, starting 20:34:27 UTC)


# Start MIXED benchmarks
[1/11] Creating namespace 'warp-benchmark'...
Namespace 'warp-benchmark' already exists. Switching to it.
Already on project "warp-benchmark" on server "https://api.ocp4-dr.test.com:6443".
[2/11] Deleting and re-creating ObjectBucketClaim warp-benchmark-bucket-tf7w...
Deleting found OBCs...
objectbucketclaim.objectbucket.io "warp-benchmark-bucket-tf7w" deleted
objectbucketclaim.objectbucket.io/warp-benchmark-bucket-b79e created
[3/11] Waiting for OBC to be bound (provisioning bucket)...
Waiting for bucket provisioning...
OBC is Bound.
[4/11] Extracting credentials...
Endpoint: s3.openshift-storage.svc
Bucket:   warp-bucket-b605c401-3db9-4296-bb98-47805fe3eb3f
[5/11] Clenup old Warp Running Pod
Deleting old 'warp-runner' pod...
Old pod removed.
[6/11] Deploying Warp Runner Pod...
pod/warp-runner created
Waiting for Pod to be Ready...
pod/warp-runner condition met
..............................
[10/11] Running MIXED Benchmark...
---------------------------------------------------
>>> Starting MIXED Benchmark (30s)...
    Ratio: 50% GETs + 50% PUTs + 0% DELETEs + 0% STATs 
    Saving to: /tmp/custom-run-mixed-20260109-203557.json.zst
>>> Analyzing MIXED Results:


Report: GET (191 reqs). Ran Duration: 28s, starting 20:36:11 UTC
 * Objects per request: 1. Size: 1572864 bytes. Concurrency: 10.
 * Average: 9.06 MiB/s, 6.04 obj/s (28s)
 * Reqs: Avg: 463.4ms, 50%: 424.8ms, 90%: 875.9ms, 99%: 1268.8ms, Fastest: 32.0ms, Slowest: 1720.5ms, StdDev: 291.4ms
 * TTFB: Avg: 397ms, Best: 22ms, 25th: 192ms, Median: 388ms, 75th: 589ms, 90th: 728ms, 99th: 987ms, Worst: 1.208s StdDev: 243ms

Throughput, split into 28 x 1s:
 * Fastest: 16.1MiB/s, 10.72 obj/s (1s, starting 20:36:35 UTC)
 * 50% Median: 9.1MiB/s, 6.10 obj/s (1s, starting 20:36:26 UTC)
 * Slowest: 2.4MiB/s, 1.61 obj/s (1s, starting 20:36:12 UTC)

──────────────────────────────────

Report: PUT (204 reqs). Ran Duration: 28s, starting 20:36:11 UTC
 * Objects per request: 1. Size: 1572864 bytes. Concurrency: 10.
 * Average: 10.34 MiB/s, 6.89 obj/s (28s)
 * Reqs: Avg: 996.5ms, 50%: 1104.2ms, 90%: 1496.9ms, 99%: 1681.8ms, Fastest: 301.2ms, Slowest: 1992.8ms, StdDev: 430.5ms

Throughput, split into 28 x 1s:
 * Fastest: 14.2MiB/s, 9.45 obj/s (1s, starting 20:36:31 UTC)
 * 50% Median: 10.4MiB/s, 6.92 obj/s (1s, starting 20:36:27 UTC)
 * Slowest: 5.8MiB/s, 3.88 obj/s (1s, starting 20:36:09 UTC)


──────────────────────────────────

Report: Total (395 reqs). Ran Duration: 28s, starting 20:36:11 UTC
 * Objects per request: 1. Size: 1572864 bytes. Concurrency: 10.
 * Average: 19.40 MiB/s, 12.93 obj/s (28s)

Throughput, split into 28 x 1s:
 * Fastest: 24.4MiB/s, 16.29 obj/s (1s, starting 20:36:18 UTC)
 * 50% Median: 19.5MiB/s, 13.01 obj/s (1s, starting 20:36:30 UTC)
 * Slowest: 14.4MiB/s, 9.62 obj/s (1s, starting 20:36:12 UTC)

#------ Phase: Cleanup -------#
Deleting OBC: warp-benchmark-bucket-b79e...
objectbucketclaim.objectbucket.io "warp-benchmark-bucket-b79e" deleted
pod "warp-runner" deleted
---------------------------------------------------
[11/11] Benchmarks Complete.
---------------------------------------------------

-------------------- NOTES ------------------------
---------------------------------------------------
The output includes throughput measured in MB/s showing data transfer rates.
Operations per second display how many GET / PUT requests the system can handle.
Latency percentiles show response times at p50, p90, p99, and p99.9 levels for operations.
Links:
Throughput -> https://docs.min.io/enterprise/minio-warp/reference/#throughput
Operations per second -> https://docs.min.io/enterprise/minio-warp/reference/#operations-per-second
Latency percentiles -> https://docs.min.io/enterprise/minio-warp/reference/#latency-metrics
[root@dr-ocp-bastion-server ~]# 
~~~
